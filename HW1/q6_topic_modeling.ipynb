{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM85j1-ZX8RZ"
   },
   "source": [
    "\n",
    "### Submission Instructions:\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE`, and that no tests fail.  \n",
    "\n",
    "Note: on Colab, To use a GPU, do the following: Runtime$\\rightarrow$Change runtime type$\\rightarrow$ GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BH7SiwY0X8L5"
   },
   "source": [
    "**Acknowledgements**: This notebook was writen with the help of the following\n",
    "[turturial](https://towardsdatascience.com/understanding-topic-coherence-measures-4aa41339634c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "0u1IYgCZJtVd"
   },
   "outputs": [],
   "source": [
    "! pip install datasets\n",
    "! pip install bertopic\n",
    "! pip install --upgrade gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKNJ7dq-7KwH"
   },
   "source": [
    "# Loading 20_newsgroups dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lNXocN6Lncu"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# YOUR CODE HERE: fill which dataset (from HuggingFace hub) to use\n",
    "hf_ds = None\n",
    "# END\n",
    "newsgroups_dataset = load_dataset(hf_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpwDmhPnP85G"
   },
   "outputs": [],
   "source": [
    "newsgroups_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AX0YjXM-RkI5"
   },
   "outputs": [],
   "source": [
    "# Lets look on example from the dataset:\n",
    "next(iter(newsgroups_dataset['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM2MuXKA7FGE"
   },
   "source": [
    "## Loading BERTopic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUGX0uXt7hxJ"
   },
   "source": [
    "TODO: This part should be done by them, write some general insterction, and tell them to polt topic info, and to create a model_topics variable which contain the list of topics (list of list of strs). Also ask them what k (number of words in topic) the model that they use have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "J33hB4oJEOXF"
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "# YOUR CODE HERE: fill model (from HuggingFace hub) to use\n",
    "hf_model = None\n",
    "# END\n",
    "\n",
    "topic_model = BERTopic.load(hf_model)\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info\n",
    "# Note from BERTopic doc: Topic number -1 refers to all outliers and should typically be ignored. Next, let's take a look at the most frequent topic that was generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "a6NDNhNFUNeC"
   },
   "outputs": [],
   "source": [
    "model_topics = topic_info['Representation'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAaI3UUQ8TWV"
   },
   "source": [
    "# Evaluation using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6akZi26U9ky"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "tokenizer = lambda s: re.findall( '[\\w\\d]+', s.lower() )\n",
    "texts = [tokenizer(s['text']) for s in newsgroups_dataset['test']]\n",
    "\n",
    "word2id = Dictionary(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wtyps6rTRf7Z"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: fill which metric to use (supported according to CoherenceModel documentation):\n",
    "coherence_metrice_1 = None\n",
    "coherence_metrice_2 = None\n",
    "\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "lfiXE5qwTFwM"
   },
   "outputs": [],
   "source": [
    "cm_1 = CoherenceModel(topics = model_topics, texts=texts,  dictionary=word2id, coherence=coherence_metrice_1)\n",
    "print(f\"{coherence_metrice_1}: {round(cm_1.get_coherence(), 2)}\")\n",
    "cm_2 = CoherenceModel(topics = model_topics, texts=texts,  dictionary=word2id, coherence=coherence_metrice_2)\n",
    "print(f\"{coherence_metrice_2}: {round(cm_2.get_coherence(), 2)}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
